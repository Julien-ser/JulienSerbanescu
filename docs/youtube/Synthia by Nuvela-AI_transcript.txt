This is the user interface review of Cynthia,  which is a service that makes research papers smarter  through AI, specifically model context protocols.  So first, let's create a project.  We're going to create our paper.  So I have this previously loaded example  where it's unanswered building and question answering frameworks.  That'll be my name.  And this will be the summary of what the paper entails.  This is similar to a task I worked over the summer.  So this is a bit relating to me,  and I understand this task a bit more.  Let's create this new project.  So as we create a new project,  we'll see it's under list of papers.  We have our details.  And then under fragments,  this is where the model context protocol really sets in.  As based on a pine cone database,  it will be able to load in certain fragments of other papers  that have relevant pieces of information  to what exactly we're looking for.  For example, this fragment,  this segment of this introduction  to unanswered building paper  is going to be very important in our papers.  So it suggests we can use that.  Then we have causes of hallucination in LLAMS,  hallucination of large language models, et cetera.  And they all just have their own unique features  and in fragments.  So we start with 10 by default.  You could add your own fragments.  You could also delete existing fragments,  like I deleted those two.  Let's say I want to do MRC sentiment analysis.  And then we're going to enter it in.  Author, we're going to do Mark Noble.  Let's just let's just say Mark Noble.  And then year 2015,  summary using machinery reading comprehension  in order to find user sentiment.  Something like that.  And then we'll just enter a certain,  like a dev post link or we'll put in a GitHub link for now.  If we add the fragment, you'll see it's here.  And if we go to source, it will be accessed.  Now, these other sources,  they are just proxy papers for now.  But as we implement it and we load our kind of code database,  it will have actual papers within it.  Now from here, there are many things we could do.  Let's start with generating citations.  So this will take our existing paper fragments.  And it will show us, oh,  based on, they have predefined authors in years.  And based on that, we loaded them in a citation form.  And now, alumni would help us use different methods as well.  And this would also be another tool  that the model context protocol system using  and topic would actually be able to execute within it.  So as you see, these are all citations we have.  We also have another feature called source analysis  where, again, we do one more semantic match  with our project summary and title.  And we semantically match with each of these fragments,  user added and normal.  And then we would get sort of a percent match.  Like, oh, for example, using the squad 2.0 database  is 94% accurate to what we're actually detailing  with our paper,  detecting unanswerable questions, similar story there.  As you can see,  it's a very robust system that gives more insights  into the paper author as to, oh, here's some sources  that you can use.  Here's how accurate they are to what you want to use.  And it helps just make research smarter, more efficient,  and better for users overall.  Now, this last feature,  it gives you a generated paper.  It will generate some late-tech code.  And it'll also show you a preview  of what this may look like otherwise.  Again, this is sort of proxy data based off  of our existing fragments.  And another tool set from a model context protocol  will be able to do this.  Again, we also implement a code here and betting as well,  just to make sure we have a vector database  so every semantic match would work perfectly.  Even this generation would work well as well.  But I think a more general L1 would be more implemented here.  And finally, for a PDF preview,  it also gives us our actual,  or an actual PDF-looking document of this sort  based on our existing formatted proxy late-tech code.  So that's my overview for our Cynthia front-end  or user experience throughout the process.  Obviously, the backend would make this a bit more robust  and customizable towards the user,  using features such as model context protocol,  cohere, embedding, pine cone database storage.  And obviously, running it on in the topic  would be the thing with model context protocol.  Thank you very much for listening.